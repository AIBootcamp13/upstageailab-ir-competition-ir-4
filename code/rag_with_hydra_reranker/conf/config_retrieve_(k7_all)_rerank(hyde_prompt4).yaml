# LLM 설정
llm:
  model: "solar-pro2"  # solar-pro2, gemini-2.5-flash, gemini-2.5-flash-lite 등 사용 가능
  delay_seconds: 0  # Gemini rate limit 회피를 위한 각 호출 전 대기 시간 (초)
  # model: "gemini-2.5-flash-lite"  # solar-pro2, gemini-2.5-flash, gemini-2.5-flash-lite 등 사용 가능
  # delay_seconds: 7  # Gemini rate limit 회피를 위한 각 호출 전 대기 시간 (초)
  retry_max: 10  # LLM 호출 재시도 최대 횟수
  retry_delay_seconds: 30  # 재시도 간 대기 시간(초)
  temperature: 0
  seed: 1
  timeout: 1000
  reasoning_effort: "high"
  cache:
    enabled: true
    dir: "cache/llm"

# 평가 설정
eval:
  max_iterations: 0  # 0이면 제한 없음

# QA 설정
qa:
  use_final_answer: false  # false면 검색만, true면 검색 결과로 별도 QA 수행

# 프롬프트 설정
prompts:
  qa: |
    ## Role: 과학 상식 전문가

    ## Instructions
    - 사용자의 이전 메시지 정보 및 주어진 Reference 정보를 활용하여 간결하게 답변을 생성한다.
    - 주어진 검색 결과 정보로 대답할 수 없는 경우는 정보가 부족해서 답을 할 수 없다고 대답한다.
    - 한국어로 답변을 생성한다.
  
  function_calling: |
    ## Role: 과학 상식 전문가

    ## Instruction
    - 먼저 질문이 chit-chat 즉, 지극히 개인적질문이나 안부, 인사, 감정에 대한 질문 일 경우에는 절대로 search api를 호출하지 말고 적절한 대답을 생성한다.
    - chit-chat 즉, 지극히 개인적질문이나 안부, 인사, 감정에 대한 질문 이외에는 무조건 반드시 search api를 호출해야 하고 스스로 판단해서 대답하면 안된다.
    - 과학 상식 범위 내에서 설명 가능하더라도 반드시 search api를 호출해야 한다.
    - 추가 검색 없이도 과학 상식으로 설명 가능한 범위이더라도 반드시 search api를 호출해야 한다.
    - 어떤 사건에 관한것이거나 코드 프로그램적인 질문을 하더라도 반드시 search api를 호출해야 한다.
    - 평균을 구하는 코드 질문인경우 반드시 search api를 호출해야 한다.
    - search api를 호출할 때는 반드시 질문에 대한 최종 korean query를 생성해서 호출해야 한다.

  standalone_query_description: "Final korean query suitable for use in search from the user messages history."

  hyde: |
    질문에 대해서 아래 예시와 같은 문장 스타일과 길이로 답변해줘.
    
    - 예시 답변 1 :
    건강한 사람이 에너지 균형을 평형 상태로 유지하는 것은 중요합니다. 에너지 균형은 에너지 섭취와 에너지 소비의 수학적 동등성을 의미합니다. 일반적으로 건강한 사람은 1-2주의 기간 동안 에너지 균형을 달성합니다. 이 기간 동안에는 올바른 식단과 적절한 운동을 통해 에너지 섭취와 에너지 소비를 조절해야 합니다. 식단은 영양가 있는 식품을 포함하고, 적절한 칼로리를 섭취해야 합니다. 또한, 운동은 에너지 소비를 촉진시키고 근육을 강화시킵니다. 이렇게 에너지 균형을 유지하면 건강을 유지하고 비만이나 영양 실조와 같은 문제를 예방할 수 있습니다. 따라서 건강한 사람은 에너지 균형을 평형 상태로 유지하는 것이 중요하며, 이를 위해 1-2주의 기간 동안 식단과 운동을 조절해야 합니다.
    - 예시 답변 2 :
    수소, 산소, 질소 가스의 혼합물에서 평균 속도가 가장 빠른 분자는 수소입니다. 수소 분자는 가장 가볍고 작은 원자로 구성되어 있기 때문에 다른 분자들보다 더 빠르게 움직입니다. 이러한 이유로 수소 분자는 주어진 온도에서 가장 빠른 평균 속도를 가지고 있습니다. 수소 분자는 화학 반응에서도 활발하게 참여하며, 수소 연료로도 널리 사용됩니다. 따라서 수소 분자는 주어진 온도에서 평균 속도가 가장 빠른 분자입니다.

# HyDE 전역 설정
hyde:
  use_original_query: false  # true면 원본 사용자 쿼리 사용, false면 standalone_query 사용

# Dense 전역 스위치(ANN/Exact)
dense:
  mode: ann  # ann | exact
  metric: cosine  # exact 전용: cosine | dot | l2 (mode=exact에서만 사용)

# 리트리브 설정
retrieve:
  sparse:
    enabled: true   # sparse retrieve 활성화 여부
    top_k: 7       # sparse_retrieve에서 가져올 문서 수
  dense_upstage:
    enabled: true   # Upstage 임베딩 기반 dense 활성화 여부
    model_name: "solar-embedding-1-large"
    top_k: 7       # dense_retrieve_upstage에서 가져올 문서 수
    num_candidates: 500  # KNN 후보 수
  dense_sbert:
    enabled: true   # SBERT 임베딩 기반 dense 활성화 여부
    model_name: "snunlp/KR-SBERT-V40K-klueNLI-augSTS"
    top_k: 7       # dense_retrieve_sbert에서 가져올 문서 수
    num_candidates: 500  # KNN 후보 수
  dense_upstage_hyde:
    enabled: true  # HyDE 기법을 활용한 Upstage 임베딩 활성화 여부 (dense_upstage와 동일한 모델 사용)
    top_k: 7       # dense_retrieve_upstage_hyde에서 가져올 문서 수
    num_candidates: 500  # KNN 후보 수
  dense_gemini:
    enabled: true  # Gemini 임베딩 기반 dense 활성화 여부
    model_name: "models/gemini-embedding-001"  # Gemini 임베딩 모델 (3072차원)
    top_k: 7       # dense_retrieve_gemini에서 가져올 문서 수
    num_candidates: 500  # KNN 후보 수
    batch_size: 100  # 배치 처리 크기 (rate limit 회피)
    batch_delay_seconds: 65  # 배치 처리 후 대기 시간 (초)
  dense_gemini_hyde:
    enabled: true  # HyDE 기법을 활용한 Gemini 임베딩 활성화 여부
    top_k: 7       # dense_retrieve_gemini_hyde에서 가져올 문서 수
    num_candidates: 500  # KNN 후보 수
    batch_size: 100  # 배치 처리 크기 (rate limit 회피)
    batch_delay_seconds: 65  # 배치 처리 후 대기 시간 (초)

# 리랭커 설정
reranker:
  use_reranker: true
  use_hyde: true  # HyDE 기법으로 가상 문서 생성하여 리랭킹 여부
  model_name: "Qwen/Qwen3-Reranker-8B"
  batch_size: 4
  # 공식 가이드 기반 지시문/템플릿 설정
  instruction: "The given Query and Document are highly relevant."
  format_template: |
    <Instruct>: {instruction}
    <Query>: {query}
    <Document>: {doc}
  system_prefix: |
    <|im_start|>system
    Judge whether the Document meets the requirements based on the Query and the Instruct provided. Note that the answer can only be "yes" or "no".<|im_end|>
    <|im_start|>user
  assistant_suffix: |
    <|im_end|>
    <|im_start|>assistant
    <think>
    
    </think>
    
  max_length: 8192
  true_token: "yes"
  false_token: "no"
  top_k: 3        # 리랭킹 후 최종 선택할 문서 수
  
# 임베딩 배치 설정 (모델명은 각 retrieve 섹션에 정의)
embedding:
  batch_size: 100

query_embedding:
  cache:
    enabled: true
    dir: "cache/qemb"

# 로깅 설정
logging:
  show_hyde_generated_document: true  # HyDE로 생성된 가상 문서 출력 여부
  show_retrieved_docids: true  # 각 리트리브 방식별 가져온 docid 리스트 출력 여부

# 인덱스 설정
index:
  force_recreate: false  # true면 활성화된 방식의 인덱스만 재생성
  sparse:
    name: "index_sparse"
  upstage:
    name: "index_upstage"
  sbert:
    name: "index_sbert"
  gemini:
    name: "index_gemini"

# Elasticsearch 설정
elasticsearch:
  username: "elastic"
  hosts: ["https://localhost:9200"]
  # ca_certs: "/data/ephemeral/home/elasticsearch-8.8.0/config/certs/http_ca.crt"
  ca_certs: "/data/ephemeral/home/elasticsearch-9.0.3/config/certs/http_ca.crt"

# 파일 경로 설정
paths:
  documents: "../../input/data/documents.jsonl"
  eval_data: "../../input/data/eval.jsonl"
  output: "submission.csv"  # Hydra가 자동으로 outputs/{date}/{time}/ 폴더에 저장
